
self.add_argument('id', 'default', comment='Experiment ID')
self.add_argument('seed', 123, comment='Random seed')
self.add_argument('game', 'pong', comment='ATARI game')
self.add_argument('T_max', int(10e6), comment='Number of training steps (4x number of frames)')
self.add_argument('max_episode_length', int(108e3), comment='Max episode length (0 to disable)')
self.add_argument('history_length', 4, comment='Number of consecutive states processed (ATARI)')  # 1 for MFEC (originally), 4 for MFEC (in NEC paper) and NEC
self.add_argument('algorithm', 'NEC', comment='Algorithm')
self.add_argument('hidden_size', 512, comment='Hidden size')
self.add_argument('key_size', 128, comment='Key size')  # 64 for MFEC, 128 for NEC
self.add_argument('num_neighbours', 50, comment='Number of nearest neighbours')  # 11 for MFEC, 50 for NEC
self.add_argument('separation_beta', 1, comment='Separation Beta')
self.add_argument('memory_capacity', int(1e5), comment='Experience replay memory capacity')
self.add_argument('dictionary_capacity', int(5e5), comment='Dictionary capacity (per action)')  # 1e6 for MFEC, 5e5 for NEC
self.add_argument('replay_frequency', 4, comment='Frequency of sampling from memory')
self.add_argument('episodic_multi_step', 100, comment='Number of steps for multi-step return from end of episode')  # Infinity for MFEC, 100 for NEC
self.add_argument('epsilon_initial', 1, comment='Initial value of ε-greedy policy')
self.add_argument('epsilon_final', 0.001, comment='Final value of ε-greedy policy')  # 0.005 for MFEC, 0.001 for NEC
self.add_argument('epsilon_anneal_start', 5000, comment='Number of steps before annealing ε')
self.add_argument('epsilon_anneal_end', 25000, comment='Number of steps to finish annealing ε')
self.add_argument('discount', .99, comment='Discount factor')  # 1 for MFEC, 0.99 for NEC
self.add_argument('learning_rate', 7.92468721e-6, comment='Network learning rate')
self.add_argument('rmsprop_decay', 0.95, comment='RMSprop decay')
self.add_argument('rmsprop_epsilon', 0.01, comment='RMSprop epsilon')
self.add_argument('rmsprop_momentum', 0, comment='RMSprop momentum')
self.add_argument('dictionary_learning_rate', 0.1, comment='Dictionary learning rate')
self.add_argument('kernel', 'mean_IDW', comment='Kernel function')  # mean for MFEC, mean_IDW for NEC
self.add_argument('kernel_delta', 1e-3, comment='Mean IDW kernel delta')
self.add_argument('batch_size', 32, comment='Batch size')
self.add_argument('learn_start', 50000, comment='Number of steps before starting training')  # 0 for MFEC, 50000 for NEC
self.add_argument('evaluate', False, comment='Evaluate only')
self.add_argument('evaluation_interval', 1000, comment='Number of training steps between evaluations')
self.add_argument('evaluation_episodes', 10, comment='Number of evaluation episodes to average over')
self.add_argument('evaluation_size', 500, comment='Number of transitions to use for validating Q')
self.add_argument('evaluation_epsilon', 0, comment='Value of ε-greedy policy for evaluation')
self.add_argument('checkpoint_interval', 0, comment='Number of training steps between saving buffers (0 to disable)')
self.add_argument('render', False, comment='Display screen (testing only)')